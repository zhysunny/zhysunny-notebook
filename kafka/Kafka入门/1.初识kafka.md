# 初识kafka

## 简介
* Kafka是Linkedin于2010年12月份开源的消息系统
* 一种分布式的、基于发布/订阅的消息系统
* 特点：
	* 消息持久化：通过O(1)的磁盘数据结构提供数据的持久化(顺序读写)
	* 高吞吐量：每秒百万级的消息读写 partition
	* 分布式：扩展能力强
	* 多客户端：java、php、python、c++
	* 实时性：生产者生产的message立即被消费者可见

## 消息队列

|-|ActiveMQ|RabbitMQ|Kafka|
|------|------|------|------|
|所属公司/社区|Apache|Mozilla Public License|Apache/Linkedin|
|开发语言|Java|Eriang|Scala|
|支持的协议|OpenWire、STOMP、REST、XMPP、AMQP|AMQP|仿AMQP|
|事务|支持|不支持|不支持|
|集群|支持|支持|支持|
|负载均衡|支持|支持|支持|
|动态扩容|不支持|不支持|支持|

## AMQP协议
* **消费者(Consumer)**：从消息队列中请求消息的客户端应用程序
* **生产者(Producer)**：向broker发布消息的客户端应用程序
* **AMQP服务器端(broker)**：用来接收生产者发送的消息并将这些消息路由给服务器中的队列

## Kafka架构
* **主题(Topic)**：一个主题类似新闻中的体育、娱乐、教育等分类概念，在实际工程中通常一个业务一个主题
* **分区(Partition)**：一个topic中的消息数据按照多个分区组织，分区是kafka消费队列组织的最小单位，一个分区可以看做是一个FIFO的队列。

## 基本组件
* **Broker**：每一台机器叫一个Broker
* **Producer**：日志消息生产者，用来写数据，比如：flume sink和kafka
* **Consumer**：消息的消费者，用来读数据，比如spark streaming
* **Topic**：不同消费者去指定的Topic中读，不同的生产者往不同Topic中写
* **Partition**：在Topic基础上做了进一步区分分层
	* 比如Topic为‘test’，2个分区test-0 test-1
* Kafka内部是分布式的，一个Kafka集群通常包括多个Broker
* zookeeper负载均衡：将topic分成多个分区，每个Broker存储一个或多个partition
* 多个Producer和Consumer同时生产和消费消息

## Topic
* 一个Topic是一个用于发布消息的分类或feed名，kafka集群使用分区的日志，每个分区都是有顺序且不变的消息序列
* commit的log可以不断追加，消息在每个分区中都分配了一个叫offset的id序列来唯一识别分区中的消息
* 举例：若创建topic1和topic2两个topic，且分别有13个和19个分区，则整个集群上会相应生成共32个文件夹
	* topic1 13个分区 topic1-【0-12】
	* topic2 19个分区 topic2-【0-18】
* 无论发布的消息是否被消费，kafka都会持久化一定时间或空间的数据量(可配置)
* 在每个消费者都会持久化这个offset在日志中，通常消费者读消息时会使offset值线性的增长，但实际上其位置是由消费者控制，它可以按任意顺序来消费消息，比如复位到老的offset来重新处理
* 每个分区代表一个并行单元

## Message
* message(消息)是通信的基本单位，每个producer可以向一个topic(主题)发布一些消息，如果Consumer订阅了这个主题，那么新发布的消息就会广播给这些Consumer
* message format：
	* message length：4 byte -1 空
	* "magic" value:1 byte kafka服务协议版本号(做兼容)
	* crc:4 byte
	* timestamp:8 byte
	* payload:n byte
	
## Producer
* 生产者可以发布数据到它指定的topic中，并可以指定topic里哪些消息分配到哪些分区(比如简单的轮流分发各个分区或通过指定分区语义分配key到对应分区)
* 生产者直接把消息发送给对应分区的broker，而不需要任何路由层
* 批处理发送，当message积累到一定数量或等待一定时间后进行发送

## Consumer
* 一种更抽象的消费方式：消费组(consumer groupid) streaming
* 该方式包含了传统的queue和发布订阅方式
	* 首先消费者标记自己一个消费组名，消息将投递到每个消费组中的某一个消费者实例上
	* 如果所有的消费者实例都有相同的消费组，这样就像传统的queue方式
	* 如果所有的消费者实例都有不同的消费组，这样就像传统的发布订阅方式
	* 消费组就好比是个逻辑的订阅者，每个订阅者由许多消费者实例构成(用于扩展或容错)
* 相对于传统的消息系统，kafka拥有更强壮的顺序保证
* 由于topic采用了分区，可在多Consumer进程操作时保证顺序性和负载均衡

## 持久化
* kafka存储布局简单：Topic的每个partition对应一个逻辑日志(一个日志为相同大小的一组分段文件)
* 每次生产者发布消息到一个分区，代理就将消息追加到最后一个段文件。**当发布的消息数量达到设定值或者经过一段时间后，一段文件真正flush磁盘中**，写入完成后，消息公开给消费者
* 与传统的消息系统不同，kafka系统中存储的消息没有明确的消息id
* 消息通过日志中的**逻辑偏移量**来公开

## 传输效率
* 生产者提交一批消息作为一个请求，消费者虽然利用api遍历消息是一个一个的，但背后也是一次请求获取一批数据，从而减少网络请求数量
* kafka层采用无缓存设计，而是依赖于底层的文件系统页缓存，这有助于避免双重缓存，即消息只缓存了一份在页缓存中，同时这在kafka重启后保持缓存warm也有额外的优势，因kafka根本不缓存消息在进程中，故gc开销也就很小
* zero-copy：kafka为了减少字节拷贝，采用了大多数系统都会提供的sendfile系统调用

## 无状态的Broker
* kafka代理是无状态的：意味着消费者必须维护已消费的状态信息offset，这些信息由消费者自己维护，代理完全不管，这种设计非常微妙，它本身包含了创新
	* 从代理删除消息变得很棘手，因为代理并不知道消费者是否已经使用该消息，kafka创新性地解决了这个问题，它将一个简单的基于时间的SLA应用于保留策略，当消息在代理中超过一定时间后，将会被自动删除
	* 这种创新设计有很大的好处，消费者可以故意倒回到老的偏移量再次消费数据，这违反了队列的常见约定，但被证明是许多消费者的基本特征

## 交付保证
* kafka默认采用at least once的消息投递策略，即在消费者端的处理顺序是获得消息->处理消息->保存位置，这可能导致一旦客户端挂掉，新的客户端接管时处理前面客户端已经处理过的消息
* 三种保证策略：
	* at most once消息可能会丢，但绝不会重复传输
	* at lease once消息绝不会丢，但可能会重复传输
	* exactly once每条消息肯定会被传输一次且仅传输一次

## 副本管理
* kafka将日志复制到指定多个服务器上
* 副本的单元是partition，在正常情况下，每个分区有一个leader和0到多个follower
* leader处理对应分区上所有的读写请求，分区可以多于broker数，leader也是分布式的
* follower的日志和leader的日志是相同的，follower被动的复制leader，如果leader挂了，其中一个follower会自动变成新的leader
* 和其他分布式系统一样，节点“活着”定义在于我们能否处理一些失败情况，kafka需要两个条件保证是“活着”
	* 节点在zookeeper注册的session还在且可维护(基于zookeeper心跳机制)
	* 如果是slave则能够紧随leader的更新不至于落得太远
* kafka采用in sync来代替“活着”
	* 如果follower挂掉或卡住或落得很远，则leader会移除同步列表中的in sync，至于落得多远才叫远由replica.max.messages配置，而表示副本“卡住”由replica.lag.time.max.ms配置

## 分布式协调
* 由于kafka中一个topic中的不同分区只能被消费组的一个消费者消费，就避免了多个消费者消费相同的分区时会导致额外的开销(如要协调哪个消费者消费哪个消息，还有锁及状态的开销)。kafka中消费进程只需要在代理和同组消费者有变化时进行一次协调(这种协调不是经常性的，故可以忽略开销)
* kafka使用zookeeper做以下事情：
	* 探测broker和consumer的添加和移除
	* 当1发生时触发每个消费者进程重新负载
	* 维护消费关系和追踪消费者在分区消费的消息的offset

## kafka生产者性能测试优势
* kafka不等待代理的确认，以代理能处理的最快速度发送消息
* kafka有更高效的存储格式，平均而言，kafka每条消息有9字节开销，而ActiveMQ有144字节，其原因是JMS所需的沉重消息头，以及维护各种索引结构的开销，Linkedin注意到ActiveMQ一个最忙的线程大部分时间都在存取B-Tree以维护消息元数据和状态

## kafka消费者性能测试优势
* kafka有更高效的存储格式，在kafka中，从代理传输到消费者的字节更少
* ActiveMQ和RabbitMQ两个容器中的代理必须维护每个消息的传输状态，Linkedin团队注意到其中一个ActiveMQ线程在测试中，一直在将kahaDB页写入磁盘，与此相反，kafka代理没有磁盘写入动作，最后，kafka通过使用sendfile API降低了传输开销
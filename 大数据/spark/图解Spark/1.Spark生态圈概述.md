# Spark生态圈概述

## Spark和MapReduce比较

* 1.Spark把中间数据放入内存，迭代效率高。MapReduce中的计算结果保存在磁盘。
* 2.Spark支持DAG图的分布式并行计算的编程框架，减少迭代过程。
* 3.Spark容错性高，弹性分布式数据集RDD如果一部分数据丢失，可以根据血缘恢复。还有checkpoint容错。
* 4.Spark更加通用，数据集操作类型大致分为transformation和action两大类

## Spark生态系统

* Spark Core
* Spark Streaming
* Spark SQL
* BlinkDB
* MLBase/MLlib
* GraphX
* SparkR
* Alluxio
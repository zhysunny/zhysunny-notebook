# Spark编程模型

## RDD操作类型

* 创建操作(Creation)：获取内存集合或者外部存储资源；通过RDD转换生成RDD
* 转换操作(Transformation)：将RDD转换成新的RDD，惰性操作，只定义新的RDD，没有执行
* 控制操作(Control)：RDD持久化
* 行动操作(Action)：能够触发Spark运行的操作

## 作业调度

对于执行失败的任务，只要它对应调度阶段父类信息仍然可用，该任务会分散到其他节点重新执行。

如果某些调度阶段不可用(例如，因为Shuffle在map节点输出丢失了)，则重新提交相应的任务，并以并行方式计算丢失的分区。

在作业中如果某个任务执行缓慢(即Straggler)，系统则会在其他节点上执行该任务的副本，并取最先得到的结果作为最终结果。

## 内存管理

* 未序列化Java对象存在内存中：性能最优。
* 序列化Java对象存在内存中：空间有限的情况下使用，降低了性能。
* 存储在磁盘：适用于RDD太大的情形，每次重新计算该RDD会带来额外的资源开销(如IO等)

对于内存使用LRU回收算法进行管理，当计算得到一个新的RDD分区，但是没有足够空间，系统会从最近最少使用的RDD回收其一个分区的空间。除非该RDD是新分区对应的RDD，这种情况下Spark会将旧的分区继续保留在内存中，防止同一个RDD的分区被循环调入调出。

## RDD编程接口

* RDD分区(Partitions)
* RDD首选位置(PreferredLocations)
* RDD依赖关系(Dependencies)
* RDD分区计算(Iterator)
* RDD分区函数(Partitioner)

## RDD创建操作

```
val array = 1 to 10
// parallelize方法
var rdd = sc.parallelize(array)
println(rdd.partitions.size)
rdd = sc.parallelize(array, 5)
println(rdd.partitions.size)
// makeRDD与parallelize方法一直
rdd = sc.makeRDD(array, 6)
println(rdd.partitions.size)
// makeRDD设置首选位置
val collect = Seq[(Int, Seq[String])]((1, Seq[String]("master", "slave1")), (2, Seq[String]("slave2", "slave3")))
rdd = sc.makeRDD(collect)
println(rdd.partitions.size)
println(rdd.preferredLocations(rdd.partitions(0)))
println(rdd.preferredLocations(rdd.partitions(1)))
// 外部存储资源
var fileRdd = sc.textFile("README.md")
println(fileRdd.count()) // 每一行记录作为rdd的一个存储单元
println(fileRdd.partitions.size)
```

其他方法：
* sc.wholeTextFiles()：读取目录的小文件，返回(用户名、内容)
* sc.sequenceFile()：读取hadoop二进制key-value形式的文件
* sc.hadoopFile()：读取hadoop文件
* sc.newAPIHadoopFile()：（新版本）读取hadoop文件
* sc.hadoopRDD()：任何hadoop输入类型转化为RDD
* sc.newAPIHadoopRDD()：（新版本）任何hadoop输入类型转化为RDD

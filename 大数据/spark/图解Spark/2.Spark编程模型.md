# Spark编程模型

## RDD操作类型

* 创建操作(Creation)：获取内存集合或者外部存储资源；通过RDD转换生成RDD
* 转换操作(Transformation)：将RDD转换成新的RDD，惰性操作，只定义新的RDD，没有执行
* 控制操作(Control)：RDD持久化
* 行动操作(Action)：能够触发Spark运行的操作

## 作业调度

对于执行失败的任务，只要它对应调度阶段父类信息仍然可用，该任务会分散到其他节点重新执行。

如果某些调度阶段不可用(例如，因为Shuffle在map节点输出丢失了)，则重新提交相应的任务，并以并行方式计算丢失的分区。

在作业中如果某个任务执行缓慢(即Straggler)，系统则会在其他节点上执行该任务的副本，并取最先得到的结果作为最终结果。

## 内存管理

* 未序列化Java对象存在内存中：性能最优。
* 序列化Java对象存在内存中：空间有限的情况下使用，降低了性能。
* 存储在磁盘：适用于RDD太大的情形，每次重新计算该RDD会带来额外的资源开销(如IO等)

对于内存使用LRU回收算法进行管理，当计算得到一个新的RDD分区，但是没有足够空间，系统会从最近最少使用的RDD回收其一个分区的空间。除非该RDD是新分区对应的RDD，这种情况下Spark会将旧的分区继续保留在内存中，防止同一个RDD的分区被循环调入调出。

## RDD编程接口

* RDD分区(Partitions)
* RDD首选位置(PreferredLocations)
* RDD依赖关系(Dependencies)
* RDD分区计算(Iterator)
* RDD分区函数(Partitioner)

## RDD创建操作

```
val array = 1 to 10
// parallelize方法
var rdd = sc.parallelize(array)
println(rdd.partitions.size)
rdd = sc.parallelize(array, 5)
println(rdd.partitions.size)
// makeRDD与parallelize方法一直
rdd = sc.makeRDD(array, 6)
println(rdd.partitions.size)
// makeRDD设置首选位置
val collect = Seq[(Int, Seq[String])]((1, Seq[String]("master", "slave1")), (2, Seq[String]("slave2", "slave3")))
rdd = sc.makeRDD(collect)
println(rdd.partitions.size)
println(rdd.preferredLocations(rdd.partitions(0)))
println(rdd.preferredLocations(rdd.partitions(1)))
// 外部存储资源
var fileRdd = sc.textFile("README.md")
println(fileRdd.count()) // 每一行记录作为rdd的一个存储单元
println(fileRdd.partitions.size)
```

其他方法：
* sc.wholeTextFiles()：读取目录的小文件，返回(用户名、内容)
* sc.sequenceFile()：读取hadoop二进制key-value形式的文件
* sc.hadoopFile()：读取hadoop文件
* sc.newAPIHadoopFile()：（新版本）读取hadoop文件
* sc.hadoopRDD()：任何hadoop输入类型转化为RDD
* sc.newAPIHadoopRDD()：（新版本）任何hadoop输入类型转化为RDD

## RDD转换操作

```
// 创建一个rdd
val array = Array(1, 4, 8, 3, 2, 1, 3, 5, 4, 2, 3, 4)
val rdd = sc.parallelize(array, 3)
println(rdd.take(array.length).toBuffer)
// ArrayBuffer(1, 4, 8, 3, 2, 1, 3, 5, 4, 2, 3, 4)
// map操作，每个数加1
println(rdd.map(x => x + 1).take(array.length).toBuffer)
// ArrayBuffer(2, 5, 9, 4, 3, 2, 4, 6, 5, 3, 4, 5)
// flatMap操作，每个数和1组成数组
println(rdd.map(x => Array(x, 1)).flatMap(x => x).take(array.length * 2).toBuffer)
// ArrayBuffer(1, 1, 4, 1, 8, 1, 3, 1, 2, 1, 1, 1, 3, 1, 5, 1, 4, 1, 2, 1, 3, 1, 4, 1)
println(rdd.distinct().take(array.length).toBuffer)
// ArrayBuffer(3, 4, 1, 8, 5, 2)
// 重分区
// 重分区大于原分区无效
rdd.coalesce(5)
// 重分区小于原分区可以
rdd.coalesce(1)
// 重分区大于原分区需要进行shuffle
rdd.coalesce(5, true)
// 相当于shuffle的coalesce
rdd.repartition(5)
// 随机分组，结果Array[RDD[T]]
rdd.randomSplit(Array(1, 4, 3, 4))
// 将每个分区放数组，结果为RDD[Array[T]]
rdd.glom()
val other = sc.parallelize(1 to 10, 4)
// union 并集不去重
rdd.union(other)
// intersection 交集去重
rdd.intersection(other)
// rdd有other没有的元素，不去重
rdd.subtract(other)
// 和map类似，不过是按照分区批量执行
rdd.mapPartitions(null, true)
// 和mapPartitions类似，不过需要设置分区索引
rdd.mapPartitionsWithIndex(null, true)
// 将相同长度的rdd组装成K-V形式
rdd.zip(other) //长度不相同抛出异常
// 键值操作
// partitionBy 按照K重分区
rdd.map((_, 1)).partitionBy(new HashPartitioner(2))
// mapValues  flatMapValues 对V操作
// combineByKey 将相同key的value组合
// foldByKey 和 combineByKey类似，方法参数不同
// reduceByKey,groupByKey 将相同key的value值合并到一个集合
// reduceByKey先进行combine再进行reduce操作，性能优于groupByKey
// 连接操作
// cogroup join fullOuterJoin leftOuterJoin rightOuterJoin subtractByKey
```

## RDD控制操作

```
val rdd = sc.parallelize(1 to 10, 3)
rdd.persist()
rdd.persist(StorageLevel.MEMORY_ONLY)
// cache 默认StorageLevel.MEMORY_ONLY
rdd.cache()
rdd.unpersist()
sc.setCheckpointDir("")
rdd.checkpoint()
```

## RDD行动操作

```
val array = Array(1, 4, 8, 3, 2, 1, 3, 5, 4, 2)
val rdd = sc.parallelize(array, 3)
println(rdd.first())
println(rdd.count())
println(rdd.reduce(_ + _))
// rdd转数组
println(rdd.collect().toBuffer)
// 不排序，取前几位
println(rdd.take(10).toBuffer)
// 默认降序排序，取前几位
println(rdd.top(3).toBuffer)
// 默认升序排序，取前几位
println(rdd.takeOrdered(10).toBuffer)
// aggregate操作
println(rdd.foreachPartition(iter => println(iter.toArray.toBuffer)))
// rdd三个分区分别是ArrayBuffer(3, 2, 1)，ArrayBuffer(1, 4, 8)，ArrayBuffer(3, 5, 4, 2)
// aggregate操作使用第一个函数对每个分区和zeroValue操作，分别得到7,14,15
// 再使用第二个函数对上面结果和zeroValue操作，得到结果37
println(rdd.aggregate(1)({ (x: Int, y: Int) => x + y }, { (x: Int, y: Int) => x + y }))
// fold和aggregate一样操作，函数相当于两个相同的
println(rdd.fold(1)({ (x: Int, y: Int) => x + y }))
// 针对key-value的rdd，找出key对应的所有value值，返回Seq[V]
println(rdd.map((_, 1)).lookup(1))
// 统计每个key出现的次数，返回Map[K,Long]
println(rdd.map((_, 1)).countByKey())
// foreach  foreachPartition  遍历
// sortBy 排序
// 存储文件操作
rdd.saveAsTextFile("")
rdd.saveAsObjectFile("") //序列化
rdd.map((_, 1)).saveAsSequenceFile("")
rdd.map((_, 1)).saveAsHadoopFile("")
rdd.map((_, 1)).saveAsHadoopDataset(null)
rdd.map((_, 1)).saveAsNewAPIHadoopFile("")
rdd.map((_, 1)).saveAsNewAPIHadoopDataset(null)
```